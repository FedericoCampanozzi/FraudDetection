{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edbf2d5d",
   "metadata": {},
   "source": [
    "# Federico Campanozzi - Progetto Data Intensive con Relazione\n",
    "                                                                                                             a.a. 2021/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364feb3a",
   "metadata": {},
   "source": [
    "## 1 - Descrizione del problema\n",
    "Il problema è di classificazione e devo determinare il valore di una variabile binaria.\n",
    "Significato dei dati :\n",
    "- step: rappresenta un'unita di tempo 1 = 1 ora.\n",
    "- type: tipo di transazione.\n",
    "- amount: somma totatle di denaro spostato.\n",
    "- nameOrig: codice del cliente che ha fatto la transazione.\n",
    "- oldbalanceOrg: somma totale nel cc prima della transazione.\n",
    "- newbalanceOrig: somma totale nel cc dopo la transazione.\n",
    "- nameDest: beneficiario.\n",
    "- oldbalanceDest: somma totale nel cc del beneficiario prima della transazione.\n",
    "- newbalanceDest: somma totale nel cc del beneficiario dopo la transazione.\n",
    "- isFraud: se è stata classificata come fraudolenta da un esperto nel settore.\n",
    "- isFlaggedFraud: se è stata classificata come fraudolenta da un algoritmo di ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d530f7f",
   "metadata": {},
   "source": [
    "## 2 - Analisi esplorativa\n",
    "Il dataset è molto vasto vasto quindi l'analisi esplorativa è stata condotta su un numero ristretto di record, giusto per capire\n",
    "la dimensionalità del problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aae328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv(\"../data/data.csv\", nrows=20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec1c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "transactions[\"type\"].value_counts().plot.pie(ax=plt.subplot(1, 3, 1));\n",
    "transactions[\"isFraud\"].value_counts().plot.pie(ax=plt.subplot(1, 3, 2));\n",
    "transactions[transactions[\"isFraud\"] == 1][\"type\"].value_counts().plot.pie(ax=plt.subplot(1, 3,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701d986",
   "metadata": {},
   "source": [
    "## 3 - Modelli Predittivi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d11079b",
   "metadata": {},
   "source": [
    "import delle librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8ad54d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb8129",
   "metadata": {},
   "source": [
    "Suddivisione del training set e validation set con il metodo holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cbc34c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "f_numeric = [\"amount\",\"oldbalanceOrg\",\"newbalanceOrig\",\"oldbalanceDest\",\"newbalanceDest\"]\n",
    "f_categoric = [\"type\"]\n",
    "\n",
    "X = transactions[f_numeric+f_categoric]\n",
    "y = transactions[[\"isFraud\"]]\n",
    "\n",
    "preproc = ColumnTransformer([\n",
    "            (\"numeric\",StandardScaler(),f_numeric),\n",
    "            (\"categorical\",OneHotEncoder(),f_categoric)\n",
    "        ],remainder=\"drop\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 1/3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a5564e",
   "metadata": {},
   "source": [
    "definiamo alcune funzioni di utiliotà per la valutazione degli alberi di regressione "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c22c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_real, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred /y_real - 1) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0342ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_real, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred /y_real - 1) ** 2))\n",
    "def print_eval(X, y, model):\n",
    "    y_pred = model.predict(X)\n",
    "    print(f\"MSE       : {mean_squared_error(y, y_pred):12.4f}\")\n",
    "    print(f\"R-squared : {r2_score(y, y_pred):12.4f}\")\n",
    "    print(f\"RMSPE     : {rmspe(y, y_pred):12.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb9232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_2(X, y, model):\n",
    "    y_pred = model.predict(X)    \n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    print(\"Confusion Matrix : \")\n",
    "    print(cm)\n",
    "    print(f\"PRECISION  : {precision_score(y, y_pred):12.4f}\")\n",
    "    print(f\"RECALL     : {recall_score(y, y_pred):12.4f}\")\n",
    "    print(f\"F1-MEASURE : {f1_score(y, y_pred, average='macro'):12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8828c1b",
   "metadata": {},
   "source": [
    "## 3.1 - Alberi di Regressione"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d1f646",
   "metadata": {},
   "source": [
    "### 3.1.1 - XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12016265",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_XGBoost = Pipeline([\n",
    "    (\"preproc\", preproc),\n",
    "    (\"XGBoost\", XGBClassifier(objective='reg:squarederror', \n",
    "                    learning_rate = 0.01577, \n",
    "                    reg_lambda = 0.008, \n",
    "                    reg_alpha = 0.0001, \n",
    "                    n_estimators = 1025, \n",
    "                    verbose_eval = False))\n",
    "])\n",
    "\n",
    "model_XGBoost.fit(X_train, y_train)\n",
    "print(f\"R^2 = {model_XGBoost.score(X_val, y_val)}\")\n",
    "print_eval_2(X_val, y_val,model_XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_XGBoost.named_steps[\"XGBoost\"].feature_importances_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2daa456",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_XGBoost.named_steps[\"XGBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25523f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_XGBoost = Pipeline([\n",
    "    (\"preproc\", preproc),\n",
    "    (\"XGBoost\", XGBRegressor(objective='reg:squarederror', \n",
    "                    learning_rate = 0.01577, \n",
    "                    reg_lambda = 0.008, \n",
    "                    reg_alpha = 0.0001, \n",
    "                    n_estimators = 1025, \n",
    "                    verbose_eval = False))\n",
    "])\n",
    "\n",
    "model_XGBoost.fit(X_train, y_train)\n",
    "print(f\"R^2 = {model_XGBoost.score(X_val, y_val)}\")\n",
    "print_eval(X_val, y_val,model_XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_XGBoost.named_steps[\"preproc\"].transformers_[1][1].get_feature_names(f_categoric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73917d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_XGBoost.named_steps[\"preproc\"].transformers_[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb8c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_XGBoost.named_steps[\"preproc\"].transformers_[1][1].get_feature_names(f_categoric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b16bc",
   "metadata": {},
   "source": [
    "## 3.1.2 Logistic Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "796e2e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Federico\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Federico\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 = 0.9955002249887506\n",
      "Confusion Matrix : \n",
      "[[6443  194]\n",
      " [  14   16]]\n",
      "PRECISION  :       0.0762\n",
      "RECALL     :       0.5333\n",
      "F1-MEASURE :       0.5587\n"
     ]
    }
   ],
   "source": [
    "model_RegLos = Pipeline([\n",
    "    (\"preproc\", preproc),\n",
    "    (\"RegLoss\", LogisticRegression(solver=\"saga\", random_state=11,class_weight={1:45}))\n",
    "])\n",
    "model_RegLos.fit(X_train, y_train)\n",
    "print(f\"R^2 = {model_svm.score(X_val, y_val)}\")\n",
    "print_eval_2(X_val, y_val,model_RegLos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afff8d9",
   "metadata": {},
   "source": [
    "## 3.3 - SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b9b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = Pipeline([\n",
    "    (\"preproc\", preproc),\n",
    "    (\"SVM\", SVC(kernel='rbf',random_state=42))\n",
    "])\n",
    "model_svm.fit(X_train, y_train)\n",
    "print(f\"R^2 = {model_svm.score(X_val, y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a59733",
   "metadata": {},
   "source": [
    "## 3.4 - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95c432",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = transactions[[\"type\",\"amount\",\"oldbalanceOrg\",\"newbalanceOrig\"]]\n",
    "y = transactions[[\"isFraud\"]]\n",
    "X_train, x_val, y_train, y_val = train_test_split(X, y, test_size=1/3, random_state=42)\n",
    "\n",
    "X_scaler = ColumnTransformer([\n",
    "        (\"numeric\",StandardScaler(),[\"amount\", \"oldbalanceOrg\", \"newbalanceOrig\"]),\n",
    "        (\"categorical\",OneHotEncoder(),[\"type\"])\n",
    "    ],remainder=\"drop\")\n",
    "\n",
    "Y_scaler = StandardScaler()\n",
    "\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "x_val = X_scaler.transform(x_val)\n",
    "y_train = Y_scaler.fit_transform(y_train)\n",
    "y_val = Y_scaler.transform(y_val.values)\n",
    "\n",
    "model_nn = Sequential([\n",
    "    Dense(8, activation=\"relu\", input_dim=8),\n",
    "    Dense(1)\n",
    "])\n",
    "model_nn.summary()\n",
    "model_nn.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
    "fit_history = model_nn.fit(X_train, y_train, batch_size=2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fit_history.history[\"loss\"], \"ro-\")\n",
    "plt.legend([\"Loss (Mean Square Error)\"])\n",
    "plt.xlabel(\"Epochs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cad144",
   "metadata": {},
   "source": [
    "grazie alla classe KerasRegressor possiamo usare le potenzialità di Kerar unite al concetto di Pipeline, GridSearh ecc..\n",
    "di scikit-lean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fad520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nn(nodes, inpDim):\n",
    "    model = Sequential([\n",
    "        Dense(nodes, activation=\"relu\", input_dim=inpDim),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231cc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transactions[[\"type\",\"amount\",\"oldbalanceOrg\",\"newbalanceOrig\"]]\n",
    "y = transactions[[\"isFraud\"]]\n",
    "\n",
    "X_train, x_val, y_train, y_val = train_test_split(X, y, test_size=1/3, random_state=42)\n",
    "\n",
    "model_nn = Pipeline([\n",
    "    (\"preproc\", ColumnTransformer([\n",
    "        (\"numeric\",StandardScaler(),[\"amount\", \"oldbalanceOrg\", \"newbalanceOrig\"]),\n",
    "        (\"categorical\",OneHotEncoder(),[\"type\"])\n",
    "    ],remainder=\"drop\")),\n",
    "    (\"NN\", KerasRegressor(build_fn=build_nn, nodes=32, inpDim=8, epochs=3, batch_size=1000))\n",
    "])\n",
    "model_nn.fit(X_train, y_train)\n",
    "y_pred = model_nn.predict(x_val)\n",
    "print(f\"R^2 = {r2_score(y_val, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9da71",
   "metadata": {},
   "source": [
    "## 4 - Valutazione\n",
    "i modelli migliori si sono rilevati .... .\n",
    "Su questi implementerò una gridsearch per la ricerca degli iperparametri migliori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "kf = KFold(3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c6663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"XGBoost__learning_rate\": [0.01577,0.001577,0.01477,0.04577]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model_XGBoost, grid, cv=kf)\n",
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs.cv_results_).sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3b1c8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"SVM__degree\": [3, 4],\n",
    "    \"SVM__kernel\": ['linear', 'poly', 'rbf']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model_svm, grid, cv=kf)\n",
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b2065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(gs.cv_results_).sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fffb18",
   "metadata": {},
   "source": [
    "## 5 - Conclusioni \n",
    "In conclusione le features più rilevanti sono ... \n",
    "Il modello migliore è\n",
    "Gli iperparametri che non danno overfitting sono ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4911f",
   "metadata": {},
   "source": [
    "## 6. Link alle risorse\n",
    "#### Link al dataset di kaggle\n",
    "https://www.kaggle.com/datasets/rupakroy/online-payments-fraud-detection-dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
